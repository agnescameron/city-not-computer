
<document>
<h1>Constructing a Framework for Participatory Data Analysis</h1>
 
<p>In a mission for self-awareness, cities have long sought to rationalize complex social problems through data, quantification, and the wisdom of academics and scientists. In the late-1950s and 1960s, there was budding optimism that cybernetics, a nascent field developed by, among others, MIT mathematician Norbert Wiener and Bell labs engineer Claude Shannon, could be adapted from the field of security intelligence and applied to the problems of cities.[1] Before long, planners began to push for a more scientific approach to process and analyze urban information systems.  In response to civil unrest and racially-motivated violence in American cities in the late 1960s, the federal government formed the Kerner Commission, whose findings contributed to the creation and funding of a number of academic think tanks to better quantify and simulate the impacts of policy on welfare and housing. More recently, cities have been looking to private consultants from business intelligence and data management to help wrangle and analyze data in the service of making city services operate more smoothly. Each of these movement have reinforced the power of outsiders as having an unbiased, more rational image of the city.</p>

<p>However, in doing so, these external fields have pushed their priorities­—such as uniformity, efficiency, and control by way of surveillance—onto urban planners and policymakers. There is concern that these values have competed against and, in some cases, overcome fundamental properties of American municipal governments, such as democracy and equity. While cities have long tried to balance citizen engagement and centralized decision-making, the emergent wave of data-driven governance threatens to enshrine privileged forms of knowledge, particularly that of experts and optimization models, and deligimate deprioritized knowledge, particularly knowledge of city residents derived from their lived experience.[2]</p>

<p>So far, most efforts to engage the public in data-driven policymaking have been focused on a few small steps.[3] Generally, participation ends when residents are captured within data, their lives or interactions with the government reduced to a completed survey questionnaire or entry in a case management system. In some cases, community members have been called upon to assist in the data collection process. Participation in data collection can be justified in a number of ways: to keep staff costs down, to improve the response rate by leveraging familiarity with other community members, or to empower citizens to voice opinions about how data is being captured, but this step alone does not fully ensure that residents are involved in decision-making processes.</p>

<p>At the same time, many cities have sought to be more transparent to both their residents and outsiders by making data more available through public online data portals. However, data transparency goes beyond just making data sets available; it requires the data to be legible to citizens. Towards that end, some cities have begun to operationalize data in the form of an accessory applications (such as performance tracking applications or live transportation feed), created by either the government itself or an interested third-party. But publication is not enough; without clear information about what data sets exist in such portals and sufficient data literacy to enable residents to meaningfully utilize them, we cannot be sure that publication does not itself advance obfuscation of critical information.</p>

<p>Furthermore, as a city works to understand and analyze the social, physical, and economic reality that it’s planning for, it may be missing critical pieces of information if it is not including citizens in the data analysis and interpretation process. On one hand, if the data that is collected is untimely or unrepresentative of more granular subpopulations and areas (particularly vulnerable ones), making broad meaning of this flawed data threatens to inspire exclusionary or biased policy. On the other hand, municipal data often does not capture key components for effective policy making and implementation—such as social relationships, local power dynamics, and nuanced understandings of past benefits and harm -- that are critical to building trust, buy-in, and workability of any proposed solutions.</p>

	<div class="mid-essay">
     <div id = "canvas-container">
      <canvas id="canvas2" width="600" height="140"></canvas>
      </div>
  </div>
<p>

To ensure that municipal governments continue to maintain and plan in a manner representative of the complexity of their cities, it is important to find better avenues through which conventional quantitative and qualitative data can be considered alongside local knowledge and lived experience. Thus far, few formal exercises in participatory data analysis have been initiated by city governments. This could be, in part, because a framework for such exercises does not exist. This paper will begin to articulate such a framework, looking to the guidelines set by related fields. The next two sections lay out guidelines drawn from Public Participatory GIS and the more contemporary Equitable Open Data Guidelines created by the Detroit Digital Justice Coalition. From these examples, I hope to extract critical components that participatory data analysis efforts must incorporate to facilitate equitable and democratic knowledge creation.
 
Public Participatory GIS

Big data analytics are opening new frontiers for modeling and predictive analysis; the rise of geographic information system (GIS) software similarly disrupted disciplinary convention in the field of geography in the 1980s and 1990s. The possibilities of new types of data, new forms of representation, and more complex analytical methods created excitement around a new form of credibility for the field. However, in the 1990s, a growing group of critics began to push back against the primacy of GIS. As more social theorists began to weigh in on what was becoming a new battleground in the ‘science wars,’ practitioners began to apply Participatory Action Research methods to GIS work. Hence, the field of Public Participatory GIS (PPGIS) was born.[4]

In the intervening years, a range of PPGIS projects were initiated to understand geographic issues around the world. Different projects took different approaches to defining scope, guidelines, and techniques, but according to Sieber, the field in general was co-produced across four major dimensions: place and people, technology and data, process, and outcome and evaluation. Sieber separates these dimensions into more specific considerations and actions  (listed in Table 1) that have surfaced across PPGIS.[5] While some of these are field-specific, they combine to form a guide to the type of reflective practice that is critical in conducting equitable co-produced work.

Table 1. Sieber’s Framework for a Co-Produced PPGIS 




People and Place
Context
PPGIS must take into account specific context, and the impact of geographic scale (local, national, international) on generalizability of results
Stakeholders and Other Actors
PPGIS must be mindful of which stakeholders are included in the project, who is omitted, and how relational dynamics will impact the proceedings. 
While a consciousness of position (e.g., socioeconomic position, relative standing within a research team, status as an insider or outsider to the community or topic at hand, among others) is critical to co-creating knowledge, sometimes we are unable to completely overcome structural differences in class, race, and gender that exist outside of our project.
The Public
PPGIS has had difficulty producing results for a general public. It may instead benefit from scoping out groups of stakeholders and responding to them specifically.
Technology and Data
Extent of GIS Technology
PPGIS practitioners must be thoughtful of how technical or technologically-focused the engagement should be, and when GIS should be brought into the process. More accessible PPGIS projects generally separate community members from direct engagement with GIS software, instead encouraging them to provide input and evaluate output.
Accessibility of Data
Access to data is a critical component to the success of a PPGIS project. Clear processes to prioritize the publication of requested data and to protect individual privacy must be in place.
Appropriateness of Information
In the case that data does exist, the data must be appropriate for the work of the organization (in terms of topics, timeliness, granularity, ability to support action) and accurate (to maintain credibility of the findings).
Representation of Knowledge
Data must be representative of the various forms of knowledge found at the community-level. For that to happen, local knowledge must find a way into the work, and be transposed to fit native data structures. In the case of PPGIS, this means local knowledge must be paired with geographic points or areas.
Process
System Implementation and Sustainability
Organizations must have continued access to GIS tools to ensure the project can continue to grow and adapt to the community’s needs (especially as work continues without outside and/or academic researchers).
Participation and Communication in the Policymaking Process


The PPGIS process must acknowledge various levels of participation, and provide recourse for those unable to participate or those who are harmed in the participation process.
Decision-Making Structures and Processes
The structure of the PPGIS project influences its ability to allow for collective or transparent decision-making.
Outcomes and Evaluation
Goals and Outcomes
The problem of setting goals and measuring results in PPGIS can be difficult to navigate. Goals may be wide-ranging across different stakeholder groups and, in some cases, may even oppose one another. But perhaps the best way to address these differing goals is by making them explicit.
Measurement and Evaluation
In service of reaching those goals (or at least to help the project team keep track of their progress), defining measures of success can be difficult -- especially as causality can be difficult to pinpoint -- but necessary. 
One measure mentioned was based on appropriateness of the project to the community-based organization’s mission. Another proposes measuring empowerment through the level of participation (in the case that there is a positive relationship between the two).
Source: Summary of ‘A Framework of for a Coproduced PPGIS’ in Sieber, 2006, “Public Participation Geographic Information Systems.”

While some of these issues are more deeply rooted or unique to the field of GIS, several lessons can be taken away from this framework. As a project is initiated, it is critical to understand the impact that the scope of the project and the stakeholders involved will have on its outcome. As a project progresses, a shifting context or evolving group of stakeholders can allow for a representative or useful final output. But rather than ignore or write out the original context or group of stakeholders, it is important to document the impact these stakeholders have on the process. For participatory data analysis, this could mean showing the same set of data to different sets of stakeholders, like neighborhood residents, business owners, elected officials, etc., to get a better understanding of how different groups contextualize the same pieces of information, and how their positions and interests may impact their perceptions. Alternatively, showing roughly the same group of stakeholders different data sets over time can help them reach the level of understand or goal that they seek to achieve, but the order in which those data sets are shown and interpreted may have a bearing on how they understand future data sets.

Once the stakeholders and scope of the project are preliminarily defined, it is important to determine not only what tools, techniques, and data sets will be useful in the analysis, but how those tools, techniques, and data sets will be presented to the community researchers for their input and interpretation. In this stage, a level of capacity building may be necessary. As the project proceeds, it is important to build and implement strategies for making this work actionable, as well as sustainable, in the long run. This could entail creating a range of sessions that could be easily replicable so that the community members could continue to track and process data after any specific engagement is complete; as well as a range of tools that could be taught to others as communities change in an area, grow or shrink, or are moved.

Finally, it is important to constantly be comparing the process and its outputs to a set of shared goals, based on appropriate measures of progress. These must be decided upon collectively between the full research team (of both outside academic researchers and local community researchers), and must serve to ensure that the project is on track to reach its ultimate goal of being useful and useable by the community. 

</p>
	<div class="mid-essay">
     <div id = "canvas-container">
      <canvas id="canvas3" width="600" height="140"></canvas>
      </div>
  </div>
<p>

Detroit’s Equitable Open Data Guidelines

The second, more contemporary example comes from two critical community-based organizations influencing civic technology and data policy in Detroit—the Detroit Digital Justice Coalition (DDJC) and Detroit Community Technology Project (DCTP). DDJC is a coalition of citizens and 15 organizations (ranging from activist organizations to recreation centers and maker spaces to organizations dealing more directly with data and technology) working to advance the right to communication through the principles of access, participation, common ownership, and healthy communities. The coalition was started by Allied Media Projects in 2009 around funding from the Broadband Technology Opportunities Program (a grant program affiliated with the American Recovery and Reinvestment Act out of the US Department of Commerce), has since received funding from the Digital Trust Foundation (a foundation which was started out of a class action lawsuit against Facebook in 2009) and the Ford Foundation, and has partnered heavily with DCTP in much of its work.[6]

In 2015, the City of Detroit enacted an executive order defining its open data policy, known as the Detroit GO DATA Initiative, alongside its Open Data Portal. The order mandates that all city “data and information, unless exempt from disclosure under State or federal law, will be available to the public, starting with an open data portal,”[7] seemingly a high bar for the city to meet. To enact this policy, the executive order creates an internal Task Force and an external Advisory Commission. Currently, that committee consists primarily of city residents (including a member of the DDJC).

While the order generally aims to create, “a more transparent, open, collaborative, participatory and accountable relationship between the City government and the people it serves,”[8] it sets out no specific direction for how this open data will open up pathways to collaboration or participation. In response to the creation of the data portal, DDJC and DCTP published a set of Guidelines for Equitable Open Data in Detroit. Through rounds of public surveys, scenario brainstorming, precedent research, and interactive educational workshops, DDJC and DCTP landed on the following principles:
 
Protect the people represented by the numbers
Do not retain personal information tied to accessing City services
Publish data about all City services, even for privatized “public” services
Prioritize the release of new datasets based on community interest
Increase transparency around how data sets are defined and processed
Engage residents offline about open data
Share what’s coming next
 
While most of these guidelines set standards for privacy and security, transparency, and accountability, the sixth principle of ‘offline engagement’ seems key to community access and participation in using data. In their report, DDJC and DCTP identify digital inequity and limited access to broadband internet in the city as being limiting factors to building awareness and open data literacy. They suggest that the city needs an accompanying engagement plan that “emphasizes community dialogue and in-person training sessions,”[9] potentially modeled off of DDJC’s Data DiscoTech workshops. The DiscoTech model, short for ‘discovering technology,’ have been multimedia, interactive, and educational workshops meant to help city residents explore how technology and data may impact or benefit their communities. A series of Data DiscoTechs were specifically run around the formation of the Equitable Open Data Guidelines, providing stations on the Open Data Portal, the FOIA process, web mapping, connecting data to our bodies and lives, data visualization, and local apps.

We do not see specific mention of anything resembling collective data analysis, which is unsurprising considering that the gold standard that DDJC cites from their background research, the Sunlight Foundation’s Open Data Guidelines, is missing any mention of how to support the use of public data once it is downloaded from a portal.[10] Yet, the Equitable Open Data Guidelines lay out a couple of important insights that would make such an endeavor possible. One is definition of a well-defined conversation and action space where such an endeavor would happen. In defining the problem, DDJC and DCTP suggest that the online tutorials on how to use the open data portal from Detroit’s Department of Innovation and Technology (DoIT), the group responsible for maintaining the portal, are inaccessible to a number of community members who are likely to be affected by the availability of open data. As a response, in-person sessions are suggested to improve awareness and accessibility, particularly those that are offered in conjunction with local recreation centers and are centered around interactive learning.

To facilitate the knowledge creation process within these in-person workshops, it is critical to structure conversations around a combination of shared understanding, using techniques that encourage exploration and attempt to elevate embodied knowledge that comes from lived experience. In the case of the Data DiscoTechs, these workshops began with creating a shared awareness of the prevalence and impact of data on our everyday lives, what information is available, and some of the tools available to understand it, as well as opening up practice spaces to learn how to utilize data. Participants were encouraged to interact with existing tools of analysis and action, explore data about their neighborhoods, and discern patterns and meaning from data by visualizing it using a range of approaches. It seems as though these workshops utilized both digital and analog forms of interaction, inviting participants from all ages and varying skill sets to find meaning in the data.

Where these methods for enabling civic data for a broader population of city residents on a distribution policy level, the key lessons outlined above are illuminating when viewed through the reflective and participatory lens of PPGIS. In fact, although the documentation of the Data DiscoTech does not include explicitly mention how these workshops could be used to build common understanding and elevate local knowledge in concert with the data that is being made available, a previous publication[11] from DDJC suggests looking to Participatory Action Research techniques to help bring data down to a human scale. One such resource comes from the Data Center[12], who highlight the importance of data to test against and potentially corroborate our personal experiences. Often times, data does not uncover “new knowledge,” but instead provides evidence for well-known collective issues that may otherwise be difficult to organize around.

In addition, several other portions of the PPGIS framework could be applied to a workshop similar to the Data DiscoTech—one that is clearly situated within a community and both educates and invites participants to explore the data about their community. More clarity and intentionality about who is invited into the room and who is missing is critical to be conscious of, and perhaps something to respond to in future iterations of the workshop. In the case that the collective data analysis exercise is conducted within the context of a longer-run engagement, the appropriateness of the data and the format of the representation output can be further tailored to the needs and goals of the organization. Making those needs and goals explicit from the beginning of the engagement can also help identify appropriate evaluation criteria for the process. Finally, as the Data DiscoTech had a station devoted to teaching about the FOIA process (and generally teach action to request more data), a collective data interpretation exercise must be grounded in some form of follow-up action that can be taken to speak to power.

 
References
 
City of Detroit. About Detroit Open Data, https://data.detroitmi.gov/about. Accessed October 20, 2018.
 
Data Center, 2015. “An Introduction to Research Justice.” http://www.datacenter.org/wp-content/uploads/Intro_Research_Justice_Toolkit_FINAL1.pdf.
 
Detroit Digital Justice Coalition, 2018, “About,” http://detroitdjc.org/about/story/. 

Detroit Digital Justice Coalition and Detroit Community Technology Project, 2017. “Recommendations for Equitable Open Data,” https://github.com/datajustice/report/blob/gh-pages/downloads/DataJusticeReport.pdf.
 
Hartman, Kat. 2017. “Research Justice: Using Data at a Human Scale,” In The Opening Data Zine, Detroit Digital Justice Coalition: Detroit, MI. 35-39. https://www.alliedmedia.org/files/ddjc_zine-final-rgb.pdf
 
Light, Jennifer S. 2003. From Warfare to Welfare: Defense Intellectuals and Urban Problems in Cold War America. Baltimore: Johns Hopkins University Press.
 
Sieber, Renee. 2006. “Public Participation Geographic Information Systems: A Literature Review and Framework,”
 
Schuurman, Nadine. 2000. “Trouble in the heartland: GIS and its critics in the 1990s.” Progress in Human Geography 24 (4): 569-590.
 
Shelton, Taylor, Matthew Zook, and Alan Wiig. 2015. “The ‘Actually Existing Smart City.’” Cambridge Journal of Regions, Economy and Society 8 (1):13–25.
 
Sunlight Foundation. 2014. “Guidelines for Open Data Policies,” https://sunlightfoundation.com/opendataguidelines/.


[1] Light, 2003. From Warfare to Welfare, 36.
[2] Shelton, et al., 2016. “The ‘Actually Existing Smart City.’” 5.
[3] Ibid
[4] Schuurman, 2000, “Trouble in the heartland.”
[5] Sieber, 2006, “Public Participation Geographic Information Systems.”
[6] DDJC, About.
[7] City of Detroit, About Detroit Open Data.
[8] Ibid
[9] DDJC and DCTP, 2017, “Recommendations for Equitable Open Data.”
[10] Sunlight Foundation, 2014, “Guidelines for Open Data Policies.”
[11] Hartman, 2017. In The Opening Data Zine.
[12] Data Center, 2015. “An Introduction to Research Justice.”
</p>
</document>